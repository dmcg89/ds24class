{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  label                                               text\n",
      "0   ham  Go until jurong point, crazy.. Available only ...\n",
      "1   ham                      Ok lar... Joking wif u oni...\n",
      "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
      "3   ham  U dun say so early hor... U c already then say...\n",
      "4   ham  Nah I don't think he goes to usf, he lives aro...\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "# data = pd.read_csv('../input/spam.csv',encoding='latin-1')\n",
    "data = pd.read_csv('./spam.csv',encoding='latin-1')\n",
    "\n",
    "data = data.drop([\"Unnamed: 2\", \"Unnamed: 3\", \"Unnamed: 4\"], axis=1)\n",
    "data = data.rename(columns={\"v1\":'label', \"v2\":'text'})\n",
    "print(data.head())\n",
    "tags = data[\"label\"]\n",
    "texts = data[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Conv1D, GlobalMaxPooling1D\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing import sequence\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras import metrics\n",
    "\n",
    "num_max = 1000\n",
    "le = LabelEncoder()\n",
    "tags = le.fit_transform(tags)\n",
    "tok = Tokenizer(num_words=num_max)\n",
    "tok.fit_on_texts(texts)\n",
    "mat_texts = tok.texts_to_matrix(texts,mode='count')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test = train_test_split(texts,tags, test_size = 0.3)\n",
    "mat_texts_tr = tok.texts_to_matrix(x_train,mode='count')\n",
    "mat_texts_tst = tok.texts_to_matrix(x_test,mode='count')\n",
    "\n",
    "max_len = 100\n",
    "x_train = tok.texts_to_sequences(x_train)\n",
    "x_test = tok.texts_to_sequences(x_test)\n",
    "cnn_texts_mat = sequence.pad_sequences(x_train,maxlen=max_len)\n",
    "max_len = 100\n",
    "cnn_texts_mat_tst = sequence.pad_sequences(x_test,maxlen=max_len)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import LSTM\n",
    "\n",
    "max_features = 5000\n",
    "maxlen = 400\n",
    "batch_size = 32\n",
    "embedding_dims = 50\n",
    "filters = 250\n",
    "kernel_size = 3\n",
    "hidden_dims = 250\n",
    "epochs = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_model(model,xtr,ytr,xts,yts):\n",
    "    model.fit(xtr,ytr,batch_size=32,epochs=10,verbose=1,validation_split=0.3)\n",
    "    print(' ')\n",
    "    model.evaluate(xts,yts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_LSTM_v4():    \n",
    "    model = Sequential()\n",
    "    model.add(Embedding(max_features, 128))\n",
    "    model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2,activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['acc',metrics.binary_accuracy])\n",
    "\n",
    "    print('Train...')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/drew/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2730 samples, validate on 1170 samples\n",
      "Epoch 1/10\n",
      "2730/2730 [==============================] - 29s 11ms/step - loss: 3038.4771 - acc: 0.8516 - binary_accuracy: 0.8516 - val_loss: 0.5300 - val_acc: 0.8769 - val_binary_accuracy: 0.8769\n",
      "Epoch 2/10\n",
      "2730/2730 [==============================] - 29s 11ms/step - loss: 91444371985.5141 - acc: 0.9374 - binary_accuracy: 0.9374 - val_loss: 0.3627 - val_acc: 0.9692 - val_binary_accuracy: 0.9692\n",
      "Epoch 3/10\n",
      "2730/2730 [==============================] - 29s 11ms/step - loss: 712038.0842 - acc: 0.9733 - binary_accuracy: 0.9733 - val_loss: 0.2463 - val_acc: 0.9778 - val_binary_accuracy: 0.9778\n",
      "Epoch 4/10\n",
      "2730/2730 [==============================] - 30s 11ms/step - loss: 325.5552 - acc: 0.9810 - binary_accuracy: 0.9810 - val_loss: 1.5619 - val_acc: 0.9786 - val_binary_accuracy: 0.9786\n",
      "Epoch 5/10\n",
      "2730/2730 [==============================] - 29s 11ms/step - loss: 173950292973.6938 - acc: 0.9795 - binary_accuracy: 0.9795 - val_loss: 2.5424 - val_acc: 0.9744 - val_binary_accuracy: 0.9744\n",
      "Epoch 6/10\n",
      "2730/2730 [==============================] - 29s 11ms/step - loss: 28.6701 - acc: 0.9813 - binary_accuracy: 0.9813 - val_loss: 5.4223 - val_acc: 0.9769 - val_binary_accuracy: 0.9769\n",
      "Epoch 7/10\n",
      "2730/2730 [==============================] - 29s 11ms/step - loss: 34.6081 - acc: 0.9824 - binary_accuracy: 0.9824 - val_loss: 3.0402 - val_acc: 0.9769 - val_binary_accuracy: 0.9769\n",
      "Epoch 8/10\n",
      "2730/2730 [==============================] - 29s 11ms/step - loss: 0.2208 - acc: 0.9817 - binary_accuracy: 0.9817 - val_loss: 3.8780 - val_acc: 0.9769 - val_binary_accuracy: 0.9769\n",
      "Epoch 9/10\n",
      "2730/2730 [==============================] - 31s 11ms/step - loss: 4.1686 - acc: 0.9835 - binary_accuracy: 0.9835 - val_loss: 5.3981 - val_acc: 0.9769 - val_binary_accuracy: 0.9769\n",
      "Epoch 10/10\n",
      "2730/2730 [==============================] - 30s 11ms/step - loss: 1.5014 - acc: 0.9857 - binary_accuracy: 0.9857 - val_loss: 6.7178 - val_acc: 0.9769 - val_binary_accuracy: 0.9769\n",
      " \n",
      "1672/1672 [==============================] - 5s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "m = get_LSTM_v4()\n",
    "check_model(m,cnn_texts_mat,y_train,cnn_texts_mat_tst ,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
